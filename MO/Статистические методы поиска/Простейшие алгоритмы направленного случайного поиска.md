Различают **направленный** и **ненаправленный** случайный поиск.

### Ненаправленный случайный поиск

> [!INFO] При таком поиске все последующие испытания проводят **совершенно независимо** от результатов предыдущих. Сходимость такого поиска очень мала, но имеется важное преимущество, связанное с возможностью решения [[Классификация методов оптимизации|многоэкстремальных задач]] (искать глобальный экстремум). Примером является рассмотренный [[Простой случайный поиск|простой случайный поиск]].

---

### Направленный случайный поиск

> [!INFO] В этом случае **отдельные испытания связаны между собой**. Результаты проведенных испытаний используются для формирования последующих. Сходимость таких методов, как правило, выше, но сами методы обычно приводят только к **локальным экстремумам**.

---

## Алгоритм парной пробы

В данном алгоритме четко разделены пробный и рабочий шаги.
Пусть $\bar{x}^k$ – найденное на $k$-м шаге наименьшее значение минимизируемой функции $f(\bar{x}^k)$.
По равномерному закону генерируется случайный единичный вектор $\xi$ и по обе стороны от исходной точки $\bar{x}^k$ делаются две пробы: проводим вычисление функции в точках $\bar{x}_{1,2}^k = \bar{x}^k \pm g \cdot \xi$, где $g$ - величина пробного шага.

Рабочий шаг делается в направлении наименьшего значения целевой функции. Очередное приближение $\bar{x}^{k+1}$ определяется соотношением:
$$\bar{x}^{k+1} = \bar{x}^k + \Delta \bar{x}^k = \bar{x}^k + a \cdot \xi \cdot \text{sign}(f(\bar{x}^k - g\xi) - f(\bar{x}^k + g\xi)).$$

> [!WARNING] Особенностью данного алгоритма является его **повышенная тенденция к “блужданию”**. Даже найдя экстремум, алгоритм может увести процесс поиска в сторону.