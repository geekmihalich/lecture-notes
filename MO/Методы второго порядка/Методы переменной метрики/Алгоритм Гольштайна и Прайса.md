К алгоритмам такого типа относится алгоритм Гольштайна и Прайса, который описывается следующей последовательностью действий и предназначен для минимизации выпуклых функций.

Гольштайн и Прайс использовали не (15), а проводили аппроксимацию матрицы $H(\bar{x}^k)$ при помощи разностной схемы, основанной на полуфакториальном построении (полуфакториал – произведение $n$ первых четных чисел), а затем проводили обращение матрицы. При этом для оценки $H(\bar{x}^k)$ требуется лишь информация о $f(\bar{x}^k)$ и $\nabla f(\bar{x}^k)$.

На $k$-м этапе алгоритм выглядит следующим образом. Заранее заданы величины $0 < \delta < 1/2$ и $r > 0$.

1.  Вычисляется в качестве аппроксимации $H(\bar{x}^k)$ матрица $\tilde{H}(\bar{x}^k)$, $j$-й столбец которой определяется по формуле:
    $$\nabla f(\bar{x}^k + \theta E_j) - \nabla f(\bar{x}^k),$$
    где $\theta^k = r||\bar{\phi}(\bar{x}^{k-1})||$ для $k > 0$, $\theta^0 = r$, $E_j$ – $j$-й столбец единичной матрицы $E$ размерности $n \times n$. $\bar{\phi}(\bar{x}^k)$ – вектор-столбец, определяемый в соответствии с условиями:
    *   $\checkmark \quad \bar{\phi}(\bar{x}^k) = -\nabla f(\bar{x}^k)$, если $k=0$ или $\tilde{H}(\bar{x}^k)$ сингулярна, или $\nabla^T f(\bar{x}^k) \tilde{H}^{-1}(\bar{x}^k) \nabla f(\bar{x}^k) \le 0$, так что матрица $\tilde{H}^{-1}(\bar{x}^k)$ не является положительно определенной;
    *   $\checkmark \quad \bar{\phi}(\bar{x}^k) = -\tilde{H}^{-1}(\bar{x}^k) \nabla f(\bar{x}^k)$ – в противном случае.

> [!WARNING] Заметим, что матрица $\tilde{H}(\bar{x}^k)$ не обязательно симметрическая матрица, и если $\nabla^T f(\bar{x}^k) \tilde{H}^{-1}(\bar{x}^k) \nabla f(\bar{x}^k) \le 0$, то предлагаемое направление поиска $\bar{\phi}(\bar{x}^k)$ и направление градиента $\nabla f(\bar{x}^k)$ отличаются более чем на $90^\circ$. Следовательно, $\bar{\phi}(\bar{x}^k)$ может быть направлено в сторону, в которой $f(\bar{x})$ увеличивается.

2.  Для выражения:
    $$F(\bar{x}^k, \lambda) = \frac{f(\bar{x}^k + \lambda \bar{\phi}(\bar{x}^k)) - f(\bar{x}^k)}{\lambda \nabla^T f(\bar{x}^k) \bar{\phi}(\bar{x}^k)},$$
    вычисляется $\lambda^k$ так, чтобы $\delta \le F(\bar{x}^k, \lambda^k)$ или $\delta \le F(\bar{x}^k, \lambda^k) \le 1 - \delta$, $\lambda^k \ne 1$.

> [!INFO] Эти условия нужны для того, чтобы не допускать шагов поиска, которые далеко выходят за область линейного изменения целевой функции в окрестности $\bar{x}^k$, предполагавшуюся при аппроксимации $H(\bar{x})$.

3.  Берется $\bar{x}^{k+1} = \bar{x}^k + \lambda^k \bar{\phi}(\bar{x}^k)$.
4.  Процесс заканчивается, когда $||\bar{\phi}(\bar{x}^k)|| < \varepsilon$.

> [!TIP] Параметр $r$ следует выбирать так, чтобы матрица $\tilde{H}(\bar{x}^k)$ аппроксимировала $H(\bar{x}^k)$ как можно ближе. Величина $\delta$ выбирается так, чтобы значения $f(\bar{x}^k)$, $k=1,2,\dots$, представляли собой монотонно убывающую последовательность; чем ближе значение $\delta$ к 1/2, тем в большей степени $f(\bar{x}^k + \lambda \bar{\phi}(\bar{x}^k))$ приближается к своему минимуму по $\lambda$.