В процессе поиска осуществляется работа с регулярными симплексами. Регулярные многогранники в пространстве $E^n$ называются **симплексами**. Для $n=2$ регулярный симплекс представляет собой равносторонний треугольник; при $n=3$ - тетраэдр и т.д.

Координаты вершин регулярного симплекса в $n$-мерном пространстве могут быть определены следующей матрицей $D$, в которой столбцы представляют собой вершины симплекса, пронумерованные от 1 до $(n+1)$, а строки – координаты вершин, $i=1,n$.
Матрица размерности $n \times (n+1)$ имеет вид:
$$D = \begin{pmatrix}
0 & d_1 & d_2 & \dots & d_2 \\
0 & d_2 & d_1 & \dots & d_2 \\
0 & d_2 & d_2 & \dots & d_2 \\
\dots & \dots & \dots & \dots & \dots \\
0 & d_2 & d_2 & \dots & d_1
\end{pmatrix}_{n \times (n+1)}$$
где:
$d_1 = \frac{t}{n\sqrt{2}}(\sqrt{n+1} + n-1);$
$d_2 = \frac{t}{n\sqrt{2}}(\sqrt{n+1} - 1);$
$t$ – расстояние между вершинами. При $n=2$ получим $d_1 \approx 0.9659, d_2 \approx 0.2588$.

---

## Основные операции алгоритма

В самом простом виде симплексный алгоритм заключается в следующем.
Строится регулярный симплекс. Из вершины, в которой $f(\bar{x})$ максимальна (т.1) проводится проектирующая прямая через центр тяжести симплекса.
Затем т.1 исключается и строится новый **отраженный** симплекс из оставшихся старых точек и одной новой, расположенной на проектирующей прямой на надлежащем расстоянии от центра тяжести.

Продолжение этой процедуры, в которой каждый раз исключается вершина, где целевая функция максимальна, а также использование правил уменьшения размера симплекса и предотвращение циклического движения в окрестности экстремума позволяет достаточно эффективно определять минимум для "хороших" функций.
> [!WARNING] Но для "овражных" функций такой поиск неэффективен.

В симплексном алгоритме Нелдера и Мида минимизация функций $n$ переменных осуществляется с использованием деформируемого многогранника.

Будем рассматривать $k$-ю итерацию алгоритма. Пусть $\bar{x}_i^k = [x_{i1}^k, x_{i2}^k, \dots, x_{in}^k]^T$, $i=1,\dots,(n+1)$, является $i$-й вершиной в $E^n$ на $k$-м этапе поиска, $k=0,1,2,\dots$, и пусть значения целевой функции в вершине $f(\bar{x}_i^k)$.

Отметим вершины с минимальным и максимальным значениями. И обозначим их следующим образом:
$$f(\bar{x}_h^k) = \max \{f(\bar{x}_1^k), \dots, f(\bar{x}_{n+1}^k)\},$$
$$f(\bar{x}_l^k) = \min \{f(\bar{x}_1^k), \dots, f(\bar{x}_{n+1}^k)\}.$$
Многогранник в $E^n$ состоит из $n+1$ вершин $\bar{x}_1^k, \bar{x}_2^k, \dots, \bar{x}_{n+1}^k$.

Обозначим через $\bar{x}_{n+2}^k$ **центр тяжести** вершин без точки $\bar{x}_h^k$ с максимальным значением функции. Координаты этого центра вычисляются по формуле:
$$x_{n+2,j}^k = \frac{1}{n} \sum_{i=1, i \ne h}^{n+1} x_{i,j}^k, \quad j=1,\dots,n.$$

Начальный многогранник обычно выбирается в виде регулярного симплекса (с вершиной в начале координат).
Можно начало координат поместить в центр тяжести.

Процедура отыскания вершин в $E^n$, в которых $f(\bar{x})$ имеет лучшее значение, состоит из следующих операций:
1.  [[#Отражение|Отражение]];
2.  [[#Растяжение|Растяжение]];
3.  [[#Сжатие|Сжатие]];
4.  [[#Редукция|Редукция]].

### 1. Отражение (Reflection)

Отражение представляет собой проектирование точки $\bar{x}_h^k$ через центр тяжести $\bar{x}_{n+2}^k$ в соответствии со следующим соотношением:
$$\bar{x}_{n+3}^k = \bar{x}_{n+2}^k + \alpha \cdot (\bar{x}_{n+2}^k - \bar{x}_h^k),$$
где $\alpha > 0$ – коэффициент отражения ($\alpha = 1$ обычно).

Вычисляем значение функции в найденной точке $f(\bar{x}_{n+3}^k)$.
*   Если $f(\bar{x}_{n+3}^k) \ge f(\bar{x}_h^k)$, то переходим к четвертому пункту алгоритма – операции [[#Редукция|редукции]] для текущего симплекса.
*   Если $f(\bar{x}_l^k) < f(\bar{x}_{n+3}^k) < f(\bar{x}_h^k)$, то выполняем операцию [[#Сжатие|сжатия]] для отраженного симплекса.
*   В противном случае, если $f(\bar{x}_{n+3}^k) < f(\bar{x}_l^k)$, то выполняется операция [[#Растяжение|растяжения]] для отраженного симплекса.

### 2. Растяжение (Expansion)

Эта операция заключается в следующем. Если $f(\bar{x}_{n+3}^k) < f(\bar{x}_l^k)$ (меньше минимального значения на $k$-м этапе), то вектор $(\bar{x}_{n+3}^k - \bar{x}_{n+2}^k)$ растягивается в соответствии с соотношением:
$$\bar{x}_{n+4}^k = \bar{x}_{n+2}^k + \gamma \cdot (\bar{x}_{n+3}^k - \bar{x}_{n+2}^k),$$
где $\gamma > 0$ – коэффициент растяжения ($\gamma = 2$ обычно).
*   Если $f(\bar{x}_{n+4}^k) < f(\bar{x}_l^k)$, то точкой $\bar{x}_h^k$ в новом симплексе становится точка $\bar{x}_{n+4}^k$ и процедура продолжается с операции отражения при $k = k+1$.
*   В противном случае точкой $\bar{x}_h^k$ в новом симплексе становится точка $\bar{x}_{n+3}^k$, и также переходим к операции [[#Отражение|отражения]].

### 3. Сжатие (Contraction)

Если $f(\bar{x}_{n+3}^k) > f(\bar{x}_i^k)$, $\forall i \ne h$, то вектор $(\bar{x}_h^k - \bar{x}_{n+2}^k)$ сжимается в соответствии с формулой:
$$\bar{x}_{n+5}^k = \bar{x}_{n+2}^k + \beta \cdot (\bar{x}_h^k - \bar{x}_{n+2}^k),$$
где $0 < \beta < 1$ – коэффициент сжатия ($\beta = 0.5$ обычно).

Далее переходим к операции [[#Отражение|отражения]] с $k = k+1$. Перед этим заново выбирается точка $\bar{x}_h^{k+1}$.

### 4. Редукция (Shrinkage)

Если $f(\bar{x}_{n+3}^k) > f(\bar{x}_h^k)$, то все векторы $(\bar{x}_i^k - \bar{x}_l^k)$, где $i=1,\dots,(n+1)$, уменьшаются в два раза с отсчетом от точки $\bar{x}_l^k$ по формуле:
$$\bar{x}_i^k = \bar{x}_l^k + 0.5 \cdot (\bar{x}_i^k - \bar{x}_l^k), \quad i=1,\dots,(n+1),$$
и осуществляется переход к операции [[#Отражение|отражения]] (на начало алгоритма с $k = k+1$).

---

## Критерии останова

В качестве критерия останова могут быть взяты те же критерии, что и в остальных алгоритмах. Можно также использовать критерий останова следующего вида:
$$\sqrt{\frac{1}{n+1} \sum_{i=1}^{n+1} (f(\bar{x}_i^k) - f(\bar{x}_{n+2}^k))^2} < \varepsilon.$$

> [!INFO] После того как многогранник подходящим образом промасштабирован, его размеры должны поддерживаться неизменными пока изменения в топологии задачи не потребуют многогранника другой формы.

Выбор коэффициентов $\alpha, \beta, \gamma$ обычно осуществляется эмпирически.
Чаще всего (по рекомендации авторов) выбирают $\alpha = 1, 0.4 \le \beta \le 0.6, 2 \le \gamma \le 3$.