В данном алгоритме предлагается простая стратегия поиска, в которой используются априорные сведения о топологии функции и, в то же время отвергаются уже устаревшая информация об этой функции. В интерпретации Вуда алгоритм включает два основных этапа:

1.  **исследующий поиск** вокруг базисной точки $\bar{x}^k$;
2.  **поиск по "образцу"**, т.е. в направлении, выбранном для минимизации.

Задается начальная точка поиска $\bar{x}^0$ и начальное приращение (шаг) $\Delta \bar{x}^0$, после чего начинается исследующий поиск.

### Исследующий поиск

> [!INFO] Делаем пробный шаг по переменной $x_1$, т.е. определяем точку $\bar{x}^0 + \Delta x_1^0$ и вычисляем значение функции для точки $\bar{x}' = (x_1^0 + \Delta x_1^0, x_2^0, \dots, x_n^0)$.

*   Если значение функции в данной точке больше, чем значение функции $f(\bar{x}^0)$, то делаем пробный шаг по этой же переменной, но в противоположном направлении.
*   Если значение функции в точке $\bar{x}'' = (x_1^0 - \Delta x_1^0, x_2^0, \dots, x_n^0)$ также больше, чем $f(\bar{x}^0)$, то оставляем точку $\bar{x}^0$ без изменений.
*   Иначе заменяем точку $\bar{x}^0$ на $\bar{x}'$ или на $\bar{x}''$ в зависимости от того, где значение функции меньше исходного.

Из вновь полученной точки делаем пробные шаги по оставшимся координатам, используя тот же самый алгоритм.

> [!WARNING] Если в процессе исследующего поиска не удается сделать ни одного удачного пробного шага, то $\Delta \bar{x}$ необходимо **скорректировать** (уменьшить). После чего вновь переходим к исследующему поиску.

> [!INFO] Если в процессе исследующего поиска сделан хоть один удачный пробный шаг, то переходим к поиску по образцу.

### Поиск по образцу

После исследующего поиска мы получаем точку $\bar{x}^{01}$. Направление $\bar{x}^{01} - \bar{x}^0$ определяет оценку направления, в котором функция уменьшается. Поэтому проводим минимизацию функции в указанном направлении, решая задачу:
$$\min_{\lambda} f(\bar{x}^0 + \lambda \cdot (\bar{x}^{01} - \bar{x}^0)).$$

В поиске по "образцу" величина шага по каждой переменной пропорциональна величине шага на этапе исследующего поиска. В результате поиска по "образцу" находим новое приближение $\bar{x}^1 = \bar{x}^0 + \lambda^0 \cdot (\bar{x}^{01} - \bar{x}^0)$, где
$$\lambda^0 = \arg \min_{\lambda} f(\bar{x}^0 + \lambda \cdot (\bar{x}^{01} - \bar{x}^0)).$$
Из точки $\bar{x}^1$ начинаем новый исследующий поиск и т.д.

---

## Модификации алгоритма

Можно использовать различные модификации алгоритма, в которых, например:
*   в процессе исследующего поиска ищется минимум по каждой переменной;
*   или в процессе поиска по образцу ищется не минимум функции, а просто делается шаг в заданном найденном направлении с фиксированным значением параметра $\lambda$.