Метод Пауэлла относится к прямым методам (методам нулевого порядка). Этим методом наиболее эффективно осуществляется минимизация функций, близких к квадратичным. На каждой итерации алгоритма поиск осуществляется вдоль системы сопряженных направлений.

## Сопряженные направления

Два направления поиска $\bar{S}_i$ и $\bar{S}_j$ называются **сопряженными**, если:
$$\bar{S}_i^T H \bar{S}_j = 0, \quad i \ne j,$$
$$\bar{S}_i^T H \bar{S}_i \ge 0, \quad i = j,$$
где $H$ – положительно определенная квадратная матрица.

### Обоснование применения сопряженных направлений

В методе Пауэлла $H = \nabla^2 f(\bar{x}^k)$ - матрица вторых частных производных (Гессиан). Идеи метода Пауэлла относятся к квадратичной функции $f(\bar{x})$.

Основная идея заключается в том, что если на каждом этапе поиска определяется минимум квадратичной функции $f(\bar{x})$ вдоль каждого из $p$ ($p < n$) - сопряженных направлений и если затем в каждом из направлений делается шаг до минимальной точки, то полное перемещение от начала до шага с номером $p$ сопряжено ко всем поднаправлениям поиска.

> [!INFO] Идея использования сопряженных направлений лежит в основе ряда алгоритмов.

---

### Свойства сопряженных направлений для квадратичных функций

Отметим, что квадратичная функция может быть представлена в виде:
$$f(\bar{x}) = a + \bar{b}^T \cdot \bar{x} + \frac{1}{2} \bar{x}^T H \bar{x},$$
при этом
$$\nabla f(\bar{x}) = \bar{b} + H \bar{x}.$$
В точке минимума:
$$\nabla f(\bar{x}^*) = 0,$$
и эта точка
$$\bar{x}^* = -H^{-1} \bar{b}.$$

Заметим, что:
$$\nabla^T f(\bar{x}^k) \cdot \bar{S}^k = (\bar{S}^k)^T \cdot \nabla f(\bar{x}^k).$$

**Теорема Пауэлла:**
> [!THEOREM] Если при начальной точке $\bar{x}^0$ поиска в направлении вектора $\bar{S}$ минимум функции $f(\bar{x})$ находится к точке $\bar{x}^a$, а при начальной точке $\bar{x}^1 \ne \bar{x}^0$ поиск минимума функции $f(\bar{x})$ в том же направлении $\bar{S}$ приводит к точке $\bar{x}^b$, то при $f(\bar{x}^b) < f(\bar{x}^a)$ направление $\bar{x}^b - \bar{x}^a$ сопряжено с направлением поиска $\bar{S}$.

**Доказательство (ключевые моменты):**
Для квадратичной функции $f(\bar{x}) = a + \bar{b}^T \cdot \bar{x} + \frac{1}{2} \bar{x}^T H \bar{x}$:
В первом случае: $\bar{S}^T \cdot \nabla f(\bar{x}^a) = \bar{S}^T (H\bar{x}^a + \bar{b}) = 0$.
Аналогично, во втором случае: $\bar{S}^T \cdot \nabla f(\bar{x}^b) = \bar{S}^T (H\bar{x}^b + \bar{b}) = 0$.
Вычитая из второго выражения первое, получим, что:
$$\bar{S}^T H (\bar{x}^b - \bar{x}^a) = 0.$$
Следовательно, векторы $\bar{S}$ и $(\bar{x}^b - \bar{x}^a)$ являются сопряженными.

Эта теорема непосредственно может быть распространена на случай нескольких сопряженных направлений следующим образом.
Если, начиная из точки $\bar{x}^0$, точка $\bar{x}^a$ определяется после использования при минимизации нескольких сопряженных направлений $p$ ($p < n$). И, аналогично, если из точки $\bar{x}^1 \ne \bar{x}^0$ точка $\bar{x}^b$ определяется после использования тех же направлений и функция $f(\bar{x})$ минимизируется на каждом шаге, то вектор $(\bar{x}^b - \bar{x}^a)$ сопряжен ко всем $p$ направлениям.

---

### Применение в алгоритме

Пусть в начальный момент для двумерной задачи поиск осуществляется из точки $\bar{x}^0$ вдоль направлений, параллельных осям координат: $\bar{S}_1^0$ и $\bar{S}_2^0$.
Последовательно были найдены точки $\bar{x}_1^0, \bar{x}_2^0, \bar{x}_3^0$ (см. рис.).

Таким образом, определили 2 сопряженных направления, в которых следует вести поиск: $\bar{S}_2^0$ и $(\bar{x}_3^0 - \bar{x}_1^0)$.

В системе исходных направлений $\bar{S}_1^0$ должно быть заменено на $(\bar{x}_3^0 - \bar{x}_1^0)$, представляющее собой полное перемещение из первого минимума. Направления поиска на следующем этапе:
$\bar{S}_1^1 = \bar{S}_2^0$,
$\bar{S}_2^1 = \bar{x}_3^0 - \bar{x}_1^0$.

Второй этап начинается с минимизации вдоль направления $\bar{S}_2^1$, затем, если необходимо, перемещение в направлении $\bar{S}_1^1$.

> [!INFO] Но в случае квадратичной функции двух переменных после минимизации по двум сопряженным направлениям будет достигнута точка минимума.

---

### Общий случай алгоритма Пауэлла

В общем случае, на $k$-м шаге алгоритма Пауэлла используется $n$ линейно независимых направлений поиска.

Поиск начинается с точки $\bar{x}_0^k$ и осуществляется по следующему алгоритму:
1.  Начиная с точки $\bar{x}_0^k$, решается последовательность задач минимизации функции:
    $$\min_{\lambda} f(\bar{x}_{j-1}^k + \lambda \bar{S}_j^k), \quad j=1,\dots,n,$$
    в направлениях $\bar{S}_1^k, \dots, \bar{S}_n^k$.

При этом находятся точки $\bar{x}_1^k, \dots, \bar{x}_n^k$, которые минимизируют исходную функцию в заданных направлениях, причем:
$$\bar{x}_1^k = \bar{x}_0^k + \lambda_1 \bar{S}_1^k,$$
$$\bar{x}_2^k = \bar{x}_1^k + \lambda_2 \bar{S}_2^k,$$
...
$$\bar{x}_n^k = \bar{x}_{n-1}^k + \lambda_n \bar{S}_n^k.$$

**Ключевые соотношения:**
*   Для квадратичной функции справедливо соотношение:
    $$H^{-1} = \sum_{j=1}^n \frac{\bar{S}_j (\bar{S}_j)^T}{\bar{S}_j^T H \bar{S}_j}.$$
*   При минимизации вдоль сопряженных направлений, градиент в текущей точке ортогонален всем *предыдущим* использованным сопряженным направлениям:
    $$(\bar{S}_j^T) \cdot \nabla f(\bar{x}^l) = 0, \quad 1 \le j \le l-1.$$
*   Таким образом, точка $\bar{x}^n$, полученная в результате минимизации квадратичной функции на $n$-м шаге, **совпадает с точкой минимума** квадратичной функции $f(\bar{x})$.

> [!INFO] То есть, градиент в точке $\bar{x}^l$ ортогонален ко всем использованным ранее сопряженным направлениям.

2.  **Поиск, осуществляемый на первом этапе**, может привести к линейно зависимым направлениям, если, например, в одном из направлений $\bar{S}^i$ не удается найти меньшего значения функции. Вследствие этого 2 направления могут стать коллинеарными. Отсюда вытекает, что в системе сопряженных направлений **не следует заменять** старое направление на новое, если после такой замены направления нового набора становятся линейно зависимыми.

    На примере квадратичной функции Пауэллом было показано, что при нормировании направлений поиска в соответствии с соотношением:
    $$(\bar{S}_i^k)^T \cdot H \cdot \bar{S}_i^k = 1, \quad i=1,n,$$
    определитель матрицы, столбцы которой представляют собой направления поиска, принимает максимальное значение тогда и только тогда, когда $\bar{S}_i^k$ взаимно сопряжены относительно матрицы $H$.

    Он пришел к выводу, что направление полного перемещения на $k$-м шаге должно заменять предыдущее направление только в том случае, когда заменяющий вектор увеличивает определитель матрицы направлений поиска. Так как только тогда новый набор направлений будет более эффективным.

    Для такой проверки из точки $\bar{x}_n^k$ делается дополнительный шаг в направлении $(\bar{x}_n^k - \bar{x}_0^k)$, соответствующий полному перемещению на $k$-м этапе и получают точку $(2\bar{x}_n^k - \bar{x}_0^k)$.
    Для проверки того, что определитель матрицы направлений поиска увеличивается при включении нового направления, делается шаг 3.

3.  Если тест на шаге 2 не прошел, то ищется минимум $f(\bar{x})$ в направлении вектора $\bar{S}_{n+1}^k$, проведенного из $\bar{x}_0^k$ в $\bar{x}_n^k$:
    $$\bar{S}_{n+1}^k = (\bar{x}_n^k - \bar{x}_0^k).$$
    Точка этого минимума берется в качестве начальной точки на $(k+1)$-м этапе. А в системе сопряженных направлений сохраняются все, кроме направления $\bar{S}_m^k$ (которое дало наибольшее уменьшение функции на $k$-м шаге), которое заменяется на новое направление $\bar{S}_{n+1}^k$, но новое направление помещается в последний столбец матрицы направлений.
    На $(k+1)$-м этапе будут использоваться направления:
    $$[\bar{S}_1^{k+1}, \bar{S}_2^{k+1}, \dots, \bar{S}_n^{k+1}] = [\bar{S}_1^k, \bar{S}_2^k, \dots, \bar{S}_{m-1}^k, \bar{S}_{m+1}^k, \dots, \bar{S}_n^k, \bar{S}_{n+1}^k].$$

4.  **Критерий останова.** Алгоритм прерывается, если изменение по каждой переменной оказывается меньше заданной точности по соответствующей переменной или $||\bar{x}_n^k - \bar{x}_0^k|| \le \varepsilon$.